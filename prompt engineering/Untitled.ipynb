{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab1a8acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ede81319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "• Investment is the act of committing money or capital to an enterprise with the expectation of making a profit. \n",
      "• Investment decisions require careful research and evaluation and can be a valuable tool for building wealth and achieving financial security.\n"
     ]
    }
   ],
   "source": [
    "# Set API key\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "prompt=\"\"\"Summarize the following text into two concise bullet points:\n",
    "Investment refers to the act of committing money or capital to an enterprise with the expectation of obtaining an added income or profit in return. There are a variety of investment options available, including stocks, bonds, mutual funds, real estate, precious metals, and currencies. Making an investment decision requires careful analysis, assessment of risk, and evaluation of potential rewards. Good investments have the ability to produce high returns over the long term while minimizing risk. Diversification of investment portfolios reduces risk exposure. Investment can be a valuable tool for building wealth, generating income, and achieving financial security. It is important to be diligent and informed when investing to avoid losses.\"\"\"\n",
    "\n",
    "# Create a request to the Completion endpoint\n",
    "response = openai.Completion.create(\n",
    "  model='text-davinci-003',\n",
    "  prompt=prompt,\n",
    "  max_tokens=400,\n",
    "  temperature=1\n",
    ")\n",
    "\n",
    "print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc57ba4",
   "metadata": {},
   "source": [
    "Completions models for sentiment classification using reviews from an online shoe store called Toe-Tally Comfortable:\n",
    "\n",
    "Unbelievably good!\n",
    "Shoes fell apart on the second use.\n",
    "The shoes look nice, but they aren't very comfortable.\n",
    "Can't wait to show them off!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93cdbd9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Answer: Positive, Negative, Neutral\n"
     ]
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-003\",\n",
    "  prompt=\"\"\"\n",
    "    classify the sentiment of the following statements as either\n",
    "    negative,\n",
    "    positive, or neutral:\n",
    "    Unbelievably good!\n",
    "    Shoes fell apart on the second use.\n",
    "    The shoes look nice, but they aren't very comfortable.\n",
    "    Can't wait to show them off!\"\"\",\n",
    "  max_tokens=100\n",
    ")\n",
    "\n",
    "print(response['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54d59ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Apple: Technology \n",
      "Microsoft: Technology \n",
      "Saudi Aramco: Oil & Gas \n",
      "Alphabet: Technology \n",
      "Amazon: Retail \n",
      "Berkshire Hathaway: Conglomerate \n",
      "NVIDIA: Technology \n",
      "Meta: Technology \n",
      "Tesla: Automotive \n",
      "LVMH: Luxury Goods\n"
     ]
    }
   ],
   "source": [
    "# Create a request to the Completion endpoint to categorize \n",
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-003\",\n",
    "  prompt=\"\"\"\n",
    "      categorize the following companies: Apple, Microsoft, Saudi\n",
    "      Aramco, Alphabet, Amazon, Berkshire Hathaway, NVIDIA, Meta, Tesla,\n",
    "      and LVMH;\"\"\",\n",
    "  max_tokens=100,\n",
    "  temperature=0.5\n",
    ")\n",
    "print(response['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2eb4bc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Apple: Tech\n",
      "      Microsoft: Tech\n",
      "      Saudi Aramco: Energy\n",
      "      Alphabet: Tech\n",
      "      Amazon: Tech\n",
      "      Berkshire Hathaway: Investment\n",
      "      NVIDIA: Tech\n",
      "      Meta: Tech\n",
      "      Tesla: Tech\n",
      "      LVMH: Luxury Goods\n"
     ]
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-003\",\n",
    "  prompt=\"\"\"\n",
    "      categorize the following companies: Apple, Microsoft, Saudi\n",
    "      Aramco, Alphabet, Amazon, Berkshire Hathaway, NVIDIA, Meta, Tesla,\n",
    "      and LVMH;\n",
    "      the companies should be classified into, Tech, Energy, Luxury\n",
    "      Goods, or Investment\n",
    "      \"\"\",\n",
    "  max_tokens=100,\n",
    "  temperature=0.5\n",
    ")\n",
    "print(response['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed9e709b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A for loop and a while loop are both control flow structures used in programming to iterate over a block of code multiple times. However, they differ in the way they determine the duration and conditions of the iteration.\n",
      "\n",
      "A for loop is used when you know the exact number of times you want the loop to iterate beforehand. It typically consists of three parts: initialization, condition, and update statement. The initialization part declares a variable and initializes it to a starting value, the condition checks if the loop should continue based on a specified condition, and the update statement modifies the loop variable after each iteration. The loop will continue to execute until the condition becomes false.\n",
      "\n",
      "In contrast, a while loop is used when you want the loop to continue executing as long as a certain condition remains true. It consists of a single condition statement, and the loop will continue until the condition evaluates to false. Therefore, a while loop is more flexible than a for loop since it does not require you to specify the exact number of iterations in advance.\n",
      "\n",
      "Here's an example to illustrate the difference:\n",
      "\n",
      "Using a for loop to print numbers from 1 to 5:\n",
      "```\n",
      "for (int i = 1; i <= 5; i++) {\n",
      "    System.out.println(i);\n",
      "}\n",
      "```\n",
      "\n",
      "Using a while loop to do the same thing:\n",
      "```\n",
      "int i = 1;\n",
      "while (i <= 5) {\n",
      "    System.out.println(i);\n",
      "    i++;\n",
      "}\n",
      "```\n",
      "\n",
      "In this example, both loops will generate the same output, but the for loop is more concise when the exact number of iterations is known beforehand. The while loop can be useful when the number of iterations is not predetermined or needs to be dynamically determined during runtime.\n"
     ]
    }
   ],
   "source": [
    "# Create a request to the ChatCompletion endpoint\n",
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\",\n",
    "     \"content\": \"You are a helpful data science tutor.\"},\n",
    "    {\"role\": \"user\",\n",
    "     \"content\": \"\"\"What is the difference between a for loop and\n",
    "     a while loop?\"\"\"},\n",
    "  ]\n",
    ")\n",
    "\n",
    "# Extract and print the assistant's text response\n",
    "print(response[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7265b6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This code calculates the mean height from a dictionary of heights using the numpy library.\n"
     ]
    }
   ],
   "source": [
    "openai.api_key = \"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\"\n",
    "\n",
    "instruction = \"\"\"Explain what this Python code does in one sentence:\n",
    "import numpy as np\n",
    "\n",
    "heights_dict = {\"Mark\": 1.76, \"Steve\": 1.88, \"Adnan\": 1.73}\n",
    "heights = heights_dict.values()\n",
    "print(np.mean(heights))\n",
    "\"\"\"\n",
    "\n",
    "# Create a request to the ChatCompletion endpoint\n",
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\":\"system\",\n",
    "    \"content\":\"You are a helpful data science tutor.\"},\n",
    "    {\"role\":\"user\",\n",
    "    \"content\":instruction}\n",
    "  ],\n",
    "  max_tokens=100\n",
    ")\n",
    "\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aaa63ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The type() function returns the type or class of a given object. It can be used to determine the data type of a variable or value in Python. For example, if you have a variable x, you can use type(x) to find out whether it is an integer, string, list, etc. The type() function can also be used to compare and identify the specific type of an object.\n"
     ]
    }
   ],
   "source": [
    "##multi chat\n",
    "response = openai.ChatCompletion.create(\n",
    "   model=\"gpt-3.5-turbo\",\n",
    "   # Add a user and assistant message for in-context learning\n",
    "   messages=[\n",
    "     {\"role\": \"system\", \"content\": \"You are a helpful Python programming tutor.\"},\n",
    "     {\"role\":\"user\",\"content\":\"Explain what the min() function does\"},\n",
    "     {\"role\":\"assistant\",\"content\":\"The min() function returns the smallest item from an iterable.\"},\n",
    "     {\"role\": \"user\", \"content\": \"Explain what the type() function does.\"}\n",
    "   ]\n",
    ")\n",
    "\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2456b705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  Explain what pi is.\n",
      "Assistant:  Pi (π) is a mathematical constant that represents the ratio of the circumference of a circle to its diameter. It is an irrational and transcendental number, which means it cannot be expressed as a simple fraction or as a finite decimal.\n",
      "\n",
      "Pi is approximately equal to 3.14159, but its decimal representation goes on infinitely without repeating. The symbol \"π\" was adopted by mathematician William Jones in 1706, and it is derived from the Greek word \"periphery,\" which means circumference \n",
      "\n",
      "User:  Summarize this in two bullet points.\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Rate limit reached for default-gpt-3.5-turbo in organization org-37Hru7oXddfngouzrdh5Qy10 on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m messages\u001b[38;5;241m.\u001b[39mappend(user_dict)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Create the API request\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-3.5-turbo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\n\u001b[0;32m     19\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Convert the assistant's message to a dict and append to messages\u001b[39;00m\n\u001b[0;32m     22\u001b[0m assistant_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\openai\\api_resources\\chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[1;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\openai\\api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    279\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    287\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m    288\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[0;32m    289\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[0;32m    290\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    296\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[0;32m    297\u001b[0m     )\n\u001b[1;32m--> 298\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\openai\\api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    693\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    694\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    695\u001b[0m         )\n\u001b[0;32m    696\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[0;32m    697\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m--> 700\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    701\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    703\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    704\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    706\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    707\u001b[0m     )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\openai\\api_requestor.py:765\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    763\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[0;32m    764\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[1;32m--> 765\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[0;32m    766\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[0;32m    767\u001b[0m     )\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mRateLimitError\u001b[0m: Rate limit reached for default-gpt-3.5-turbo in organization org-37Hru7oXddfngouzrdh5Qy10 on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method."
     ]
    }
   ],
   "source": [
    "# Set your API key\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "messages = [{\"role\": \"system\", \"content\": \"You are a helpful math tutor.\"}]\n",
    "user_msgs = [\"Explain what pi is.\", \"Summarize this in two bullet points.\"]\n",
    "\n",
    "for q in user_msgs:\n",
    "    print(\"User: \", q)\n",
    "    \n",
    "    # Create a dictionary for the user message from q and append to messages\n",
    "    user_dict = {\"role\": \"user\", \"content\": q}\n",
    "    messages.append(user_dict)\n",
    "    \n",
    "    # Create the API request\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        max_tokens=100\n",
    "    )\n",
    "    \n",
    "    # Convert the assistant's message to a dict and append to messages\n",
    "    assistant_dict = dict(response[\"choices\"][0][\"message\"])\n",
    "    messages.append(assistant_dict)\n",
    "    print(\"Assistant: \", response[\"choices\"][0][\"message\"][\"content\"], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbff3d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Moderation model\n",
    "# Set your API key\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "# Create a request to the Moderation endpoint\n",
    "response = openai.Moderation.create(\n",
    "    model=\"text-moderation-latest\",\n",
    "    input=\"My favorite book is How to Kill a Mockingbird.\"\n",
    ")\n",
    "\n",
    "# Print the category scores\n",
    "print(response[\"results\"][0][\"category_scores\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a69e0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#audio-to-text-transcribe to language model\n",
    "# Set your API key\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "# Open the openai-audio.mp3 file\n",
    "audio_file = open(\"openai-audio.mp3\", \"rb\")\n",
    "\n",
    "# Create a transcript from the audio file\n",
    "response = openai.Audio.transcribe(\"whisper-1\", audio_file)\n",
    "\n",
    "# Extract and print the transcript text\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9bdce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "# Open the audio.m4a file\n",
    "audio_file= open(\"audio.m4a\",\"rb\")\n",
    "\n",
    "# Create a transcript from the audio file\n",
    "response = openai.Audio.transcribe(\"whisper-1\",audio_file)\n",
    "\n",
    "print(response[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62aeab9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
